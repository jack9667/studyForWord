topclick：模型策略 召回8%下 点击率14% -> 22%，准确率80% -> 90%
sug-news: 新闻pv约15w左右 (q1约10w, 提升50%) 10w -> 15w
news内容质量：主要广告分类+规则，突出点在textcnn，redis，sparkstream，胜出率80%，影响面15%
短视频召回优化：主要优化lucene二次排序+模型添加特征，diff胜出率70% ab点击率提升3%

数据接入平台：日量70w，不大，简单服务不考虑升级高可用性等，索引总量2亿多，新闻短视频大头1亿多，总的hbase量10个多g，存的内容不多，不会存body所以少
服务启动：xbox或ocean平台(基于docker)找对应的build.sh进行传参和打包，maven插件<artifactId>appassembler-maven-plugin</artifactId>会自动生成服务.sh文件并指定mian函数，启动给予commonthrift或者spring boot的服务

短视频二次排序：第一次用query匹配title，再这个基础上，用分词query再匹配带termweight的，modelsocre便利term匹配title，termboost+前一个term命中相邻+不相邻但相关
flexbalquery实际上是通过term及weight给定的，weight值0-1，根据weight值、idf、和抽出的实体词给term加3.0的boost
实体次抽取是通过实体次接口拿到的数据来做特征的

18年q2，q3：做接入平台，sug接新闻，sug接富样式广告
18年q4：合并topclick和sug索引，阅读准确率，topclick接新闻（全是杂活）
19年q1：sug新闻点击率提升，广告需求
19年q2：topclick点击率召回6% -> 8%下 点击率14% -> 22%
19年q3：新闻内容质量，广告分类，写redis，spark任务读kafka队列，diff G:S:B = 30:8:12 胜出率80%，影响面15%
19年q4：新闻内容质量，一堆规则，全是垃圾；接垃圾分类，广告新需求
20年q1：短视频，优化粗排二次搜索，lambdaMART特征优化，实体词、数量词，其他依赖原新闻特征，diff胜出率70% ab点击率提升1%

topclick这个位置：
就叫global-sug：
日志：特殊字段依赖日志统计，同时请求idsearch接口获取基础字段，合并发送到kafka，依赖日志的是T+1，只能等；
但同时第三方会给一份数据id --> 下载次数，与最大下载次数比率（应用方近10天的，音乐/视频和图书为播放/下载次数），也会合并基础字段
字段只更新@extra里，接入平台通过对@extra字段操作进行合并或者替换
接入平台就3个CF：D，M，X；D是基础字段，M是@extra，X预留用户自行提取
接入平台实现入hbase，入oakbay，同时计算字段（以@extra字段为基础，其格式{op+value}在data-stat内实现字段的 set/求交；发的是extra字段，处理完塞到M列，在做一层处理成oakbay需要的字段），统计查询及监控（另起一个消费者统计各source type的个数）

topclick：top特征，下载率，打分函数，ngram距离的平均值
通过日志构建@queries，一个id对应出现搜索query得搜索和点击次数；第三方给到得下载次数和下载比率；
特征：
query-> title：ngram距离（1,2,3）、tf/idf（相同term的idf和除以query总的idf和）、word2vec（cos值对query和title）、相同term占比、query命中位置比（除以title的length）、query逆序词对占比、
query对应日志特征，类别，query和@queries字段ngram距离得最大最小平均值，query和@queries得offest（位置除以length，默认无就1）最大最小平均值，搜索次数点击次数点击率（取包含query得，不包含取0），对应规则得打分函数最大最小平均值Math.pow(10, sim)*(1 + ctr)* Math.log(click +2) / 15，第三方的下载和播放比

topclick：从索引召回50条，特征训练5w条query取线上结果前10条，给0-3分，先根据query-title相关性给定具体0-3的分值，再根据其他特征调上上下，给外包团队一块做；特征50多维，ndcg@5 0.8几

算法题，系统设计，推荐架构



