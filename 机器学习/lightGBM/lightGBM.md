## 1.直方图： 
    https://blog.csdn.net/anshuai_aw1/article/details/83040541
    连续特征映射为bin值，每层分裂只遍历bins数即可，bin上存样本的梯度值和样本个数，loss左右-总的 梯度/样本数，找最大增益
    直方图可以做差，通过父节点和一个子节点求另一个

## 2.leaf-wise：
    选增益最大的节点分裂，容易过拟合

## 3.并行优化：
    水平切分，每个worker保留所有特征，合并，不同的worker合并不同特征的局部直方图，采用直方图做差算法,只需要通信一个节点的直方图

## 4.goss：
    基于梯度的one-side采样，对梯度值排序，取top a，对剩下梯度值小的b个里随机采样，并在计算增益的乘上（1-a)/b的权重，使得采样的能够近似到全集
    https://blog.csdn.net/u014411730/article/details/78816859
## 5.efb：
    独立特征合并，合并特征+确定bin范围
    贪心合并，总冲突为边，按度排序，冲突小于k合并；重新计算bin范围值
    https://www.jianshu.com/p/3daf08229d78

## 6.增益是什么：
    目标函数，梯度下降的程度，梯度代表导数，找到增益最大的说明每一步走的是下降最抖的那个方向
    增益是每次分裂集合纯度的提升，越大代表越纯，所以用来分裂节点时候用